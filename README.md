# p2-klue-hwan17(문장 내 개체간 관계 추출)

### Backgrounds (개요)

- 관계 추출(Relation Extraction)은 문장의 단어(Entity)에 대한 속성과 관계를 예측하는 문제입니다. 관계 추출은 지식 그래프 구축을 위한 핵심 구성 요소로, 구조화된 검색, 감정 분석, 질문 답변하기, 요약과 같은 자연어처리 응용 프로그램에서 중요합니다. 비구조적인 자연어 문장에서 구조적인 triple을 추출해 정보를 요약하고, 중요한 성분을 핵심적으로 파악할 수 있습니다.
- 요약된 정보를 사용해 QA 시스템 구축과 활용이 가능하며, 이외에도 요약된 언어 정보를 바탕으로 효율적인 시스템 및 서비스 구성이 가능합니다.
- 이번 대회에서는 문장, 엔티티, 관계에 대한 정보를 통해 ,문장과 엔티티 사이의 관계를 추론하는 모델을 학습시킵니다. 이를 통해 우리의 인공지능 모델이 엔티티들의 속성과 관계를 파악하며 개념을 학습할 수 있습니다. 우리의 model이 정말 언어를 잘 이해하고 있는 지, 평가해 보도록 합니다.

- input: sentence, entity1, entity2 의 정보를 입력으로 사용 합니다.

  sentence: 오라클(구 썬 마이크로시스템즈)에서 제공하는 자바 가상 머신 말고도 각 운영 체제 개발사가 제공하는 자바 가상 머신 및 오픈소스로 개발된 구형 버전의 온전한 자바 VM도 있으며, GNU의 GCJ나 아파치 소프트웨어 재단(ASF: Apache Software Foundation)의 하모니(Harmony)와 같은 아직은 완전하지 않지만 지속적인 오픈 소스 자바 가상 머신도 존재한다.
  entity 1: 썬 마이크로시스템즈
  entity 2: 오라클
  relation: 단체:별칭

- output: relation 42개 classes 중 1개의 class를 예측한 값입니다.

- 위 예시문에서 단체:별칭의 label은 6번(아래 label_type.pkl 참고)이며, 즉 모델이 sentence, entity 1과 entity 2의 정보를 사용해 label 6을 맞추는 분류 문제입니다.


### Data (데이터)

전체 데이터에 대한 통계는 다음과 같습니다. 학습에 사용될 수 있는 데이터는 train.tsv 한 가지 입니다. 주어진 데이터의 범위 내 혹은 사용할 수 있는 외부 데이터를 적극적으로 활용하세요!
- train.tsv: 총 9000개
- test.tsv: 총 1000개 (정답 라벨 blind)
- answer: 정답 라벨 (비공개)

학습을 위한 데이터는 총 9000개 이며, 1000개의 test 데이터를 통해 리더보드 순위를 갱신합니다. private 리더보드는 운영하지 않는 점 참고해 주시기바랍니다.
- label_type.pkl: 총 42개 classes (class는 아래와 같이 정의 되어 있며, 평가를 위해 일치 시켜주시길 바랍니다.) pickle로 load하게 되면, 딕셔너리 형태의 정보를 얻을 수 있습니다.

---


## **점수 및 순위:**

-   LB 점수: 79.2, 67등

## **검증 전략:**

-   제공된 train 데이터의 10%와 20%를 검증용으로 사용 (Stratify 적용)

## **사용한 모델 및 설정:**

-   모델: xlm-roberta-large, kobart, koelectra, bert-base-multilingual-cased
-   추가 젂처리: Ner tagging, Entity token 추가, Max_length=128
-   최적화: AdamW, Loss: Labelsmoothing
-   추가 시도:
    -   0 라벨 분류 학습 후, 0 라벨 포함 학습
    -   데이터 불균형 대응으로 focal loss와 labelsmoothing 적용
    -   Cosine 스케줄러 사용

## **앙상블 방법:**

-   argmax 라벨 로짓 값을 기준으로 앙상블
-   0을 포함한 모델과 0을 제외한 모델 출력 비교하여 선택

## **시도했지만 실패한 점:**

-   모델 변경 실험 결과 좋지 않았음
-   Upsampling, Entity 고려 실패
-   스케줄러 실험 실패
-   모델 파라미터 조정 어려움

## **교훈:**

-   다른 자연어 태스크 결과 활용 가능
-   전처리로 모델 학습 방향 유도 가능
-   스케줄러 이해 높일 필요
-   다양한 모델 아키텍처 이해 필요
-   불균형 데이터 손실 함수 다양하게 적용 가능

## **한계와 도전숙제:**

-   다양한 모델 아키텍처와 파라미터 실험
-   다양한 스케줄러와 학습률, 배치 크기 실험
-   EDA와 데이터 증강 다양하게 시도
-   transformers 라이브러리 활용 향상
-   새로운 모델 아키텍처와 NLP 모델 공부 및 활용 향상