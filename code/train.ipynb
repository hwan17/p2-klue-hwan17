{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfec743-24f0-4e60-9615-4b07b76ee9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2245' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2245/3810 29:41 < 20:42, 1.26 it/s, Epoch 8.83/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.543600</td>\n",
       "      <td>3.283780</td>\n",
       "      <td>0.492222</td>\n",
       "      <td>5.219900</td>\n",
       "      <td>172.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.256700</td>\n",
       "      <td>3.250870</td>\n",
       "      <td>0.492222</td>\n",
       "      <td>5.217800</td>\n",
       "      <td>172.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.265600</td>\n",
       "      <td>3.220550</td>\n",
       "      <td>0.492222</td>\n",
       "      <td>5.211800</td>\n",
       "      <td>172.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.214800</td>\n",
       "      <td>3.072523</td>\n",
       "      <td>0.567778</td>\n",
       "      <td>5.218100</td>\n",
       "      <td>172.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.009600</td>\n",
       "      <td>2.943788</td>\n",
       "      <td>0.658889</td>\n",
       "      <td>5.206000</td>\n",
       "      <td>172.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.894000</td>\n",
       "      <td>2.864519</td>\n",
       "      <td>0.721111</td>\n",
       "      <td>5.207900</td>\n",
       "      <td>172.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.848200</td>\n",
       "      <td>2.873505</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>5.203400</td>\n",
       "      <td>172.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.794900</td>\n",
       "      <td>2.820904</td>\n",
       "      <td>0.771111</td>\n",
       "      <td>5.215400</td>\n",
       "      <td>172.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.778300</td>\n",
       "      <td>2.811993</td>\n",
       "      <td>0.741111</td>\n",
       "      <td>5.239600</td>\n",
       "      <td>171.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.766400</td>\n",
       "      <td>2.798092</td>\n",
       "      <td>0.754444</td>\n",
       "      <td>5.202000</td>\n",
       "      <td>173.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.716300</td>\n",
       "      <td>2.794010</td>\n",
       "      <td>0.778889</td>\n",
       "      <td>5.207200</td>\n",
       "      <td>172.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.708300</td>\n",
       "      <td>2.825193</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>5.209200</td>\n",
       "      <td>172.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.693100</td>\n",
       "      <td>2.809277</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>5.214700</td>\n",
       "      <td>172.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.666300</td>\n",
       "      <td>2.795385</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>5.199000</td>\n",
       "      <td>173.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.669400</td>\n",
       "      <td>2.810395</td>\n",
       "      <td>0.758889</td>\n",
       "      <td>5.205800</td>\n",
       "      <td>172.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.632700</td>\n",
       "      <td>2.810961</td>\n",
       "      <td>0.778889</td>\n",
       "      <td>5.211500</td>\n",
       "      <td>172.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.633600</td>\n",
       "      <td>2.804927</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.212300</td>\n",
       "      <td>172.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.630700</td>\n",
       "      <td>2.830505</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>5.215300</td>\n",
       "      <td>172.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.617400</td>\n",
       "      <td>2.821543</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>5.215000</td>\n",
       "      <td>172.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.607200</td>\n",
       "      <td>2.817744</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>5.201200</td>\n",
       "      <td>173.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.592700</td>\n",
       "      <td>2.812927</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>5.208600</td>\n",
       "      <td>172.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.592500</td>\n",
       "      <td>2.841474</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>5.215200</td>\n",
       "      <td>172.572000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n"
     ]
    }
   ],
   "source": [
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoConfig\n",
    "from my_load_data import *\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "seed_everything(40)\n",
    "\n",
    "# load model and tokenizer\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\":[\"[ENT1]\", \"[END1]\", \"[ENT2]\", \"[END2]\"]})\n",
    "\n",
    "# load dataset\n",
    "train_dataset, dev_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\", 0.1, entity=False)\n",
    "# train_dataset, dev_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\", 0)\n",
    "#dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "\n",
    "train_label = train_dataset['label'].values\n",
    "dev_label = dev_dataset['label'].values\n",
    "\n",
    "# tokenizing dataset\n",
    "tokenized_train = tokenized_dataset(train_dataset, tokenizer)\n",
    "tokenized_dev = tokenized_dataset(dev_dataset, tokenizer)\n",
    "\n",
    "# make dataset for pytorch.\n",
    "RE_train_dataset = RE_Dataset(tokenized_train, train_label)\n",
    "RE_dev_dataset = RE_Dataset(tokenized_dev, dev_label)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# setting model hyperparameter\n",
    "auto_config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "# auto_config.attention_probs_dropout_prob = 0.5\n",
    "auto_config.num_labels = 42\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=auto_config) \n",
    "# model.parameters\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "\n",
    "# ÏÇ¨Ïö©Ìïú option Ïô∏ÏóêÎèÑ Îã§ÏñëÌïú optionÎì§Ïù¥ ÏûàÏäµÎãàÎã§.\n",
    "# https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments Ï∞∏Í≥†Ìï¥Ï£ºÏÑ∏Ïöî.\n",
    "training_args = TrainingArguments(\n",
    "output_dir='./results/xlm',          # output directory\n",
    "save_total_limit=5,              # number of total save model.\n",
    "save_steps=500,                 # model saving step.\n",
    "num_train_epochs=15,              # total number of training epochs\n",
    "learning_rate=1e-5,               # learning_rate\n",
    "per_device_train_batch_size=32,  # batch size per device during training\n",
    "per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "gradient_accumulation_steps=1,\n",
    "label_smoothing_factor=0.5,\n",
    "warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "weight_decay=0.01,               # strength of weight decay\n",
    "logging_dir='./logs/xlm',            # directory for storing logs\n",
    "logging_steps=100,              # log saving step.\n",
    "evaluation_strategy='steps', # evaluation strategy to adopt during training\n",
    "                            # `no`: No evaluation during training.\n",
    "                            # `steps`: Evaluate every `eval_steps`.\n",
    "                            # `epoch`: Evaluate every end of epoch.\n",
    "eval_steps = 100,            # evaluation step.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "args=training_args,                  # training arguments, defined above\n",
    "train_dataset=RE_train_dataset,         # training dataset\n",
    "eval_dataset=RE_dev_dataset,             # evaluation dataset\n",
    "compute_metrics=compute_metrics         # define metrics function\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4dfee8-0f69-4172-824f-84f200491825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_config.attention_probs_dropout_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc1cecb8-1c9d-49d7-bea5-b7fc5cac8e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='6750' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6750/6750 22:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>2.376332</td>\n",
       "      <td>0.524444</td>\n",
       "      <td>3.562600</td>\n",
       "      <td>505.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.866100</td>\n",
       "      <td>1.989330</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>3.534400</td>\n",
       "      <td>509.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.642000</td>\n",
       "      <td>1.946461</td>\n",
       "      <td>0.710556</td>\n",
       "      <td>3.720400</td>\n",
       "      <td>483.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.505100</td>\n",
       "      <td>2.000974</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>3.664500</td>\n",
       "      <td>491.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.432100</td>\n",
       "      <td>2.130034</td>\n",
       "      <td>0.692778</td>\n",
       "      <td>3.555100</td>\n",
       "      <td>506.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.380600</td>\n",
       "      <td>2.070653</td>\n",
       "      <td>0.734444</td>\n",
       "      <td>3.573700</td>\n",
       "      <td>503.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.365000</td>\n",
       "      <td>2.124775</td>\n",
       "      <td>0.710556</td>\n",
       "      <td>3.617200</td>\n",
       "      <td>497.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.320500</td>\n",
       "      <td>2.159071</td>\n",
       "      <td>0.716111</td>\n",
       "      <td>3.569800</td>\n",
       "      <td>504.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.297000</td>\n",
       "      <td>2.206514</td>\n",
       "      <td>0.712222</td>\n",
       "      <td>3.586600</td>\n",
       "      <td>501.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.268800</td>\n",
       "      <td>2.162366</td>\n",
       "      <td>0.721111</td>\n",
       "      <td>3.586100</td>\n",
       "      <td>501.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.259000</td>\n",
       "      <td>2.165731</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>3.530900</td>\n",
       "      <td>509.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.241600</td>\n",
       "      <td>2.171241</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>3.578400</td>\n",
       "      <td>503.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.248300</td>\n",
       "      <td>2.150781</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>3.573500</td>\n",
       "      <td>503.708000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
      "/opt/ml/code/my_load_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6750, training_loss=1.5396863923249422, metrics={'train_runtime': 1330.3261, 'train_samples_per_second': 5.074, 'total_flos': 7318578456774000.0, 'epoch': 15.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 56160256, 'train_mem_gpu_alloc_delta': 1368433664, 'train_mem_cpu_peaked_delta': 214994944, 'train_mem_gpu_peaked_delta': 1323940352})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc8ae42-7d96-407f-97ef-d8e44f24502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d139eb9e4893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# train_dataset, dev_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/opt/ml/input/data/train/train_c.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;31m#dev_dataset = load_data(\"./dataset/train/dev.tsv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/my_load_data.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dataset_dir, test_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;31m# preprecessing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/my_load_data.py\u001b[0m in \u001b[0;36mpreprocessing_dataset\u001b[0;34m(dataset, label_type, test_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mout_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'entity_01'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'entity_02'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_entity_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'blind'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/my_load_data.py\u001b[0m in \u001b[0;36madd_entity_token\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ment1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'e1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ment2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'e2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ment1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'e2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ment2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'e1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2875\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2876\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoConfig\n",
    "from my_load_data import *\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "seed_everything(40)\n",
    "\n",
    "# load model and tokenizer\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\":[\"[ENT1]\", \"[END1]\", \"[ENT2]\", \"[END2]\"]})\n",
    "\n",
    "# load dataset\n",
    "# train_dataset, dev_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train_c.tsv\", 0)\n",
    "#dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "\n",
    "train_label = train_dataset['label'].values\n",
    "# dev_label = dev_dataset['label'].values\n",
    "\n",
    "# tokenizing dataset\n",
    "tokenized_train = tokenized_dataset(train_dataset, tokenizer)\n",
    "# tokenized_dev = tokenized_dataset(dev_dataset, tokenizer)\n",
    "\n",
    "# make dataset for pytorch.\n",
    "RE_train_dataset = RE_Dataset(tokenized_train, train_label)\n",
    "# RE_dev_dataset = RE_Dataset(tokenized_dev, dev_label)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# setting model hyperparameter\n",
    "auto_config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "auto_config.num_labels = 42\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=auto_config) \n",
    "# model.parameters\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "\n",
    "# ÏÇ¨Ïö©Ìïú option Ïô∏ÏóêÎèÑ Îã§ÏñëÌïú optionÎì§Ïù¥ ÏûàÏäµÎãàÎã§.\n",
    "# https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments Ï∞∏Í≥†Ìï¥Ï£ºÏÑ∏Ïöî.\n",
    "training_args = TrainingArguments(\n",
    "output_dir='./results/ko-v3',          # output directory\n",
    "save_total_limit=10,              # number of total save model.\n",
    "save_steps=500,                 # model saving step.\n",
    "num_train_epochs=10,              # total number of training epochs\n",
    "learning_rate=5e-6,               # learning_rate\n",
    "per_device_train_batch_size=32,  # batch size per device during training\n",
    "per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "gradient_accumulation_steps=1,\n",
    "label_smoothing_factor=0.1,\n",
    "warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "weight_decay=0.01,               # strength of weight decay\n",
    "logging_dir='./logs/ko-v3',            # directory for storing logs\n",
    "logging_steps=100,              # log saving step.\n",
    "# evaluation_strategy='steps', # evaluation strategy to adopt during training\n",
    "                            # `no`: No evaluation during training.\n",
    "                            # `steps`: Evaluate every `eval_steps`.\n",
    "                            # `epoch`: Evaluate every end of epoch.\n",
    "# eval_steps = 500,            # evaluation step.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "args=training_args,                  # training arguments, defined above\n",
    "train_dataset=RE_train_dataset,         # training dataset\n",
    "# eval_dataset=RE_dev_dataset,             # evaluation dataset\n",
    "compute_metrics=compute_metrics         # define metrics function\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ab6745-0aa8-4717-a569-14b64d6574fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='monologg/koelectra-base-v3-discriminator', vocab_size=35000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[ENT1]', '[/ENT1]', '[ENT2]', '[\\\\ENT2]']})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5b8977-1b65-411c-bd1f-3f723f8c227f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ElectraEmbeddings.forward of ElectraEmbeddings(\n",
       "  (word_embeddings): Embedding(35004, 768)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.electra.embeddings.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "747520c0-9cb7-4a93-901a-ac9c7f0537e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.electra.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e62fccad-034f-49f5-8e44-57a24ef96757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,  9355,     3,  7001,     3,  6380,   146,  9853,  4556,  4073,\n",
       "          4034, 10726,  4007,  8648,  4034,  6364,    16,  6226,  4007,  6695,\n",
       "          4139,  6364,    16,  6315,  4444,  4147,  4292,  6260, 21609,  4007,\n",
       "          6483,  6318,  4292,  6311,  6364,    16,  6299, 35000,  9355,    63,\n",
       "            41, 28744,  4057,    65,  3232,  8867,  7796,   147,  2670,   146,\n",
       "          6594,  4006,  4112, 35002,  7001,    63,    41, 28744,  4097,    65,\n",
       "            16,  7744,  6283,  4047,  6261,  6284,  4219,  4195,  3771,  4820,\n",
       "          7001,    16,  3342,  6318, 10728,  3201,  4279,  4034,  7001, 24387,\n",
       "           147,  2075,  6374,  4398,  4176,    18,     3,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'labels': tensor(7)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RE_train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273ac79b-b325-454c-9854-c56344e439f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ïã¨ÏÉÅÏ†ï Ï†ïÏùòÎãπ ÎåÄÌëúÎäî 21Ïùº \"Íµ≠ÎØºÎì§ÍªòÏÑ† Ïù¥Î≤à Ï¥ùÏÑ†ÏóêÏÑú ÏßÄÏßÄÎ∂ÄÏßÑÌïú Ï†ïÏπòÍ∂åÏùò Ïù¥Ìï©ÏßëÏÇ∞Í≥º ÍººÏàòÏ†ïÏπòÎ•º Ïã¨ÌåêÌïòÍ≥† ÏßÑÏ†ïÌïú Ï†ïÏπòÌòÅÎ™ÖÏùò Í∏∏ÏùÑ Ïó¥Ïñ¥ Îã¨Îùº\"Í≥† ÎßêÌñàÎã§.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[10].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96ae2cd-fdb7-4396-a155-012116b152ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [tokenizer.decode(RE_train_dataset[i]['input_ids']) for i in range(9000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b7a5ce-9759-4cc5-83f1-98b3c1f107bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = 0\n",
    "for i in a:\n",
    "    if M < len(i):\n",
    "        M = len(i)\n",
    "        idx = i\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25960b92-2a47-47e3-bf85-323740e17477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb53205-3044-425f-9f6c-0d4464916e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 21150, 12541,  6270,  4034,  6591,  4366,     6,  6318,  4006,\n",
       "          5253,  4207,  6294,  7562,  4073,  4129, 20677,  4283,  6315,  4046,\n",
       "          4234,  3240,  4280,  4557,  4122,  4047, 16351,  4142,  4332,  4110,\n",
       "          9064,  4279,  4219,  7499,  4283,  6315, 20351,  4234,  2139,  4292,\n",
       "          3142,  4025,  7193,     6,  2075,  2633,  4398,  4176,    18,     3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_dataset.iloc[10].sentence, return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46a54266-26c7-430a-a176-09f6fbfa2ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a151aec-764b-41d6-98b8-c3147f43d054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "282f1bdc-2cc9-48ea-a0b3-1fe2a907942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
